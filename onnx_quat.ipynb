{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7071111f7d11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquantize_dynamic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQuantType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_fp32\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'assets/landmark_models/lm_model0_opt.onnx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_quant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'assets/landmark_models/lm_model0_opt_quat.onnxx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnx'"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "model_fp32 = 'assets/landmark_models/lm_model0_opt.onnx'\n",
    "model_quant = 'assets/landmark_models/lm_model0_opt_quat.onnxx'\n",
    "calibration_dataset_path = \"D:\\\\data\\\\LS3D-W.tar\\\\LS3D-W\\\\Menpo-3D\"\n",
    "#quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collect 10000 files\n",
      "input 5000\n",
      "Calibrated,quantized parameters calculated and returned.\n",
      "Calibrated and quantized model saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import re\n",
    "import abc\n",
    "import subprocess\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import helper, TensorProto, numpy_helper\n",
    "from onnxruntime.quantization import quantize_static, calibrate, CalibrationDataReader\n",
    "\n",
    "##Quat for lm model\n",
    "\n",
    "class ResNet50DataReader(CalibrationDataReader):\n",
    "    def __init__(self, calibration_image_folder, augmented_model_path='augmented_model.onnx', size_limit=0):\n",
    "        self.image_folder = calibration_image_folder\n",
    "        self.augmented_model_path = augmented_model_path\n",
    "        self.preprocess_flag = True\n",
    "        self.enum_data_dicts = []\n",
    "        self.datasize = 0\n",
    "        \n",
    "\n",
    "        self.size_limit = size_limit\n",
    "\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.preprocess_flag:\n",
    "            self.preprocess_flag = False\n",
    "            session = onnxruntime.InferenceSession(self.augmented_model_path, None)\n",
    "            (_, height, width, _) = session.get_inputs()[0].shape\n",
    "            nhwc_data_list = preprocess_func(self.image_folder, 224, 224, size_limit=self.size_limit)\n",
    "            input_name = session.get_inputs()[0].name\n",
    "            print(input_name, len(nhwc_data_list))\n",
    "            self.datasize = len(nhwc_data_list)\n",
    "            self.enum_data_dicts = iter([{input_name: nhwc_data} for nhwc_data in nhwc_data_list])\n",
    "        return next(self.enum_data_dicts, None)\n",
    "\n",
    "\n",
    "def preprocess_func(images_folder, height, width, size_limit=0):\n",
    "    '''\n",
    "    Loads a batch of images and preprocess them\n",
    "    parameter images_folder: path to folder storing images\n",
    "    parameter height: image height in pixels\n",
    "    parameter width: image width in pixels\n",
    "    parameter size_limit: number of images to load. Default is 0 which means all images are picked.\n",
    "    return: list of matrices characterizing multiple images\n",
    "    '''\n",
    "    mean = np.float32(np.array([0.485, 0.456, 0.406]))\n",
    "    std = np.float32(np.array([0.229, 0.224, 0.225]))\n",
    "    mean = mean / std\n",
    "    std = std * 255.0\n",
    "    mean = - mean\n",
    "    std = 1.0 / std\n",
    "    mean_32 = np.tile(mean, [32, 32, 1])\n",
    "    std_32 = np.tile(std, [32, 32, 1])\n",
    "    mean_224 = np.tile(mean, [224, 224, 1])\n",
    "    std_224 = np.tile(std, [224, 224, 1])\n",
    "        \n",
    "    image_names = os.listdir(images_folder)\n",
    "    if size_limit > 0 and len(image_names) >= size_limit:\n",
    "        batch_filenames = [image_names[i] for i in range(size_limit)]\n",
    "    else:\n",
    "        batch_filenames = image_names\n",
    "    unconcatenated_batch_data = []\n",
    "    print(f\"Collect {len(batch_filenames)} files\")\n",
    "    for image_name in batch_filenames:\n",
    "        if image_name.endswith(\".jpg\"):\n",
    "            image_filepath = images_folder + '/' + image_name\n",
    "            frame = cv2.imread(image_filepath, cv2.IMREAD_COLOR)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(frame, (width, height), interpolation=cv2.INTER_LINEAR)[:,:,::-1]\n",
    "            im = im * std_224 + mean_224\n",
    "            im = np.expand_dims(im, 0)\n",
    "            im = np.transpose(im, (0,3,1,2))\n",
    "            unconcatenated_batch_data.append(im)\n",
    "    batch_data = np.concatenate(np.expand_dims(unconcatenated_batch_data, axis=0), axis=0)\n",
    "    return batch_data\n",
    "\n",
    "\n",
    "dr = ResNet50DataReader(calibration_dataset_path, model_fp32, 10000)\n",
    "quantize_static(model_fp32, model_quant, dr)\n",
    "print('Calibrated and quantized model saved.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
